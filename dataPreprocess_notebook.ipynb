{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6776bf1",
   "metadata": {},
   "source": [
    "### Data Preprocessing using FunctionTransformers, ColumnTransformers and Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa88fd9",
   "metadata": {},
   "source": [
    "* After inferring required preprocessing steps in `\"dataExploration.ipnyb\"` script, preprocessing is implemented in this script.\n",
    "* Used ***FunctionTransformer*** to convert custom functions into Transformers\n",
    "* Used ***ColumnTransformer*** to perform multiple transforming steps on different columns of dataset.\n",
    "* Created ***Pipeline*** to merge all the preprocessing steps and to reuse this pipeline in predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25cec7c",
   "metadata": {},
   "source": [
    "**Predict whether a person has autism or not; using other dependent variables (Features)**\n",
    "\n",
    "\n",
    "* `ID` - ID of the patient\n",
    "* `A1_Score to A10_Score` - Score based on Autism Spectrum Quotient (AQ) 10 item screening tool\n",
    "* `age` - Age of the patient in years\n",
    "* `gender` - Gender of the patient\n",
    "* `ethnicity` - Ethnicity of the patient\n",
    "* `jaundice` - Whether the patient had jaundice at the time of birth\n",
    "* `autism` - Whether an immediate family member has been diagnosed with autism\n",
    "* `contry_of_res` - Country of residence of the patient\n",
    "* `used_app_before` - Whether the patient has undergone a screening test before\n",
    "* `result` - Score for AQ1-10 screening test\n",
    "* `age_desc` - Age of the patient\n",
    "* `relation` - Relation of patient who completed the test\n",
    "* `Class/ASD` - Classified result as 0 or 1. Here 0 represents No and 1 represents Yes. This is the target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4df2cb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imported required libraries\n",
    "try:\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import os\n",
    "    from sklearn.compose import ColumnTransformer\n",
    "    from sklearn.preprocessing import FunctionTransformer,MinMaxScaler, OneHotEncoder\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    import pickle\n",
    "\n",
    "except ModuleNotFoundError as err:\n",
    "    print('Package/Module not found in dataPreprocess.py file' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5e90cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load dataset into dataframe\n",
    "\n",
    "def load_data(filename):\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        #full_path = os.path.join(path, filename)\n",
    "        return pd.read_csv(filename)\n",
    "    \n",
    "    except FileNotFoundError as err:\n",
    "        print('Input data file is not found in dataExploration.py file')\n",
    "        print(err)\n",
    "        \n",
    "    except:\n",
    "        print('Isse when loading input CSV data in dataExploration.py file')      \n",
    "\n",
    "\n",
    "df_train = load_data('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d614877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>A1_Score</th>\n",
       "      <th>A2_Score</th>\n",
       "      <th>A3_Score</th>\n",
       "      <th>A4_Score</th>\n",
       "      <th>A5_Score</th>\n",
       "      <th>A6_Score</th>\n",
       "      <th>A7_Score</th>\n",
       "      <th>A8_Score</th>\n",
       "      <th>A9_Score</th>\n",
       "      <th>...</th>\n",
       "      <th>gender</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>jaundice</th>\n",
       "      <th>austim</th>\n",
       "      <th>contry_of_res</th>\n",
       "      <th>used_app_before</th>\n",
       "      <th>result</th>\n",
       "      <th>age_desc</th>\n",
       "      <th>relation</th>\n",
       "      <th>Class/ASD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>f</td>\n",
       "      <td>?</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>Austria</td>\n",
       "      <td>no</td>\n",
       "      <td>6.351166</td>\n",
       "      <td>18 and more</td>\n",
       "      <td>Self</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>m</td>\n",
       "      <td>?</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>India</td>\n",
       "      <td>no</td>\n",
       "      <td>2.255185</td>\n",
       "      <td>18 and more</td>\n",
       "      <td>Self</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>m</td>\n",
       "      <td>White-European</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>United States</td>\n",
       "      <td>no</td>\n",
       "      <td>14.851484</td>\n",
       "      <td>18 and more</td>\n",
       "      <td>Self</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>f</td>\n",
       "      <td>?</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>United States</td>\n",
       "      <td>no</td>\n",
       "      <td>2.276617</td>\n",
       "      <td>18 and more</td>\n",
       "      <td>Self</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>m</td>\n",
       "      <td>?</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>no</td>\n",
       "      <td>-4.777286</td>\n",
       "      <td>18 and more</td>\n",
       "      <td>Self</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  A1_Score  A2_Score  A3_Score  A4_Score  A5_Score  A6_Score  A7_Score  \\\n",
       "0   1         1         0         1         0         1         0         1   \n",
       "1   2         0         0         0         0         0         0         0   \n",
       "2   3         1         1         1         1         1         1         1   \n",
       "3   4         0         0         0         0         0         0         0   \n",
       "4   5         0         0         0         0         0         0         0   \n",
       "\n",
       "   A8_Score  A9_Score  ...  gender       ethnicity jaundice austim  \\\n",
       "0         0         1  ...       f               ?       no     no   \n",
       "1         0         0  ...       m               ?       no     no   \n",
       "2         1         1  ...       m  White-European       no    yes   \n",
       "3         0         0  ...       f               ?       no     no   \n",
       "4         0         0  ...       m               ?       no     no   \n",
       "\n",
       "   contry_of_res used_app_before     result     age_desc  relation Class/ASD  \n",
       "0        Austria              no   6.351166  18 and more      Self         0  \n",
       "1          India              no   2.255185  18 and more      Self         0  \n",
       "2  United States              no  14.851484  18 and more      Self         1  \n",
       "3  United States              no   2.276617  18 and more      Self         0  \n",
       "4   South Africa              no  -4.777286  18 and more      Self         0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b7e6685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'age_desc' column has only one value - ['18 and more']\n",
    "# 'ID' column has all unique values and acting like an index. Hence, it can be removed\n",
    "\n",
    "df_train.drop(['ID','age_desc'], axis=1, inplace= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ef4763",
   "metadata": {},
   "source": [
    "### Spliting features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7da8ec5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((800, 19), (800,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = df_train.pop('Class/ASD')\n",
    "df_train.shape, target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aee5849",
   "metadata": {},
   "source": [
    "### Design of pre-processing steps\n",
    "\n",
    "* Created 3 FunctionTransfomers from custom function for following preprocessing steps:\n",
    "        1) Handle outliers 2) Handle unkown/missing values 3) Handle rare occurring countries\n",
    "\n",
    "* Created 2 ColumnTransformers to implement following preprocessing steps\n",
    "        1) ColumnTransformer-1 = To include above mentioned 3 FunctionTransformers\n",
    "        2) ColumnTransformer-2 = To implement OneHotEncoding and Scaling\n",
    "        \n",
    "* Create 1 Piepline to merge above mentioned two ColumnTransformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af300600",
   "metadata": {},
   "source": [
    "### Handling Outliers for continuous columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f0c5c0",
   "metadata": {},
   "source": [
    "Two continuous columns in the data - *Age Column* & *Result Column*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "213aede0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutliersHandling:\n",
    "    \n",
    "    def calculate_tail(self, col):\n",
    "        \n",
    "        ''' \n",
    "        Considering a value as outlier if it is lower than lower_tail and greater than upper tail. \n",
    "        Therefore, this function calculated lower and upper tail of given column\n",
    "\n",
    "        '''\n",
    "        try:\n",
    "            q1 = col.quantile(0.25) #Lower Quartile\n",
    "            q3 = col.quantile(0.75) #Upper Quartile\n",
    "            iqr = q3 - q1                          #Calculating Inter Quartile Range (IQR)\n",
    "            upper_tail = q3 + 1.5 * iqr\n",
    "            lower_tail = q1 - 1.5 * iqr\n",
    "            return float(upper_tail), float(lower_tail)\n",
    "        \n",
    "        except Exception as err:\n",
    "            print('Issue in Calculate_tail function of OutliersHandling class')\n",
    "            print(err)\n",
    "\n",
    "    def check_outliers(self,col):\n",
    "        ''' Check total number of outliers in given continuous column'''\n",
    "        try:\n",
    "            n = 0\n",
    "            upper_tail, lower_tail = self.calculate_tail(col)\n",
    "\n",
    "            # Considering a value as outlier if it is lower than lower_tail and greater than upper tail\n",
    "            for val in col:\n",
    "                if val > upper_tail or val < lower_tail:\n",
    "                       n = n+1\n",
    "\n",
    "            print(f'Total number of outliers in the {col.name} column: ',n)\n",
    "        \n",
    "        except Exception as err:\n",
    "            print('Issue in check_outliers function of OutliersHandling class')\n",
    "            print(err)\n",
    "\n",
    "        \n",
    "    def handle_outliers(self, df):\n",
    "        ''' Replacing lower outliers with 10th percentile and upper outliers with 90th percentile '''\n",
    "        try:\n",
    "            for x in df.columns:\n",
    "\n",
    "                upper_tail, lower_tail = self.calculate_tail(df[x]) #Calling function to calculate lower and upper tail\n",
    "\n",
    "                for i in df[x].values:\n",
    "                    if i > upper_tail or i < lower_tail:\n",
    "                        if i < lower_tail:\n",
    "                            df[x].replace(i,df[x].quantile(0.10), inplace= True)\n",
    "                        else:\n",
    "                            df[x].replace(i,df[x].quantile(0.90), inplace= True)\n",
    "            return df\n",
    "\n",
    "        except Exception as err:\n",
    "            print('Issue in Calculate_tail function of OutliersHandling class')\n",
    "            print(err)\n",
    "\n",
    "outhandle_obj = OutliersHandling() # Creating Object of the class\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59353f4d",
   "metadata": {},
   "source": [
    "***Checking Outliers***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff7f38b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of outliers in the age column:  35\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m outhandle_obj\u001b[38;5;241m.\u001b[39mcheck_outliers(df_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Creating boxplot for visualization\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[43msns\u001b[49m\u001b[38;5;241m.\u001b[39mboxplot(x\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m'\u001b[39m, data\u001b[38;5;241m=\u001b[39m df_train)\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAge column before handling outliers\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sns' is not defined"
     ]
    }
   ],
   "source": [
    "outhandle_obj.check_outliers(df_train['age'])\n",
    "\n",
    "# Creating boxplot for visualization\n",
    "sns.boxplot(x= 'age', data= df_train)\n",
    "plt.title(f'Age column before handling outliers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1014896",
   "metadata": {},
   "outputs": [],
   "source": [
    "outhandle_obj.check_outliers(df_train['result'])\n",
    "\n",
    "# Creating boxplot for visualization\n",
    "sns.boxplot(x= 'result', data= df_train)\n",
    "plt.title(f'result column before handling outliers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143c2c1e",
   "metadata": {},
   "source": [
    "### Handling Missing/unkown Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fdf3a7",
   "metadata": {},
   "source": [
    "Two columns has unkown values - *ethnicity* & *relation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b27b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['ethnicity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90a597c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['relation'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71e86c2",
   "metadata": {},
   "source": [
    "**⬆️ Ethnicity and relation columns has '?' and 'others' values which seems to be unkown**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234d2cce",
   "metadata": {},
   "source": [
    "#### Transformation on country_of_res column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1472456f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['contry_of_res'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7d4574",
   "metadata": {},
   "source": [
    "Merging coutnries which are occurring less then 6 times into 'Other' category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6debe758",
   "metadata": {},
   "outputs": [],
   "source": [
    "occ = df_train['contry_of_res'].value_counts()\n",
    "\n",
    "rare_country = [con for con in occ.index if occ[con]<6]\n",
    "print(rare_country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b01667",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MissingValHandling:\n",
    "    \n",
    "    def handle_missing_values(self, df):\n",
    "        '''Replacing (\"?\" and \"others\") -> \"Others\" '''\n",
    "        try:\n",
    "            for col in df.columns:\n",
    "                df[col].replace(['?','others'],['Others','Others'], inplace= True)\n",
    "            return df\n",
    "        \n",
    "        except Exception as err:\n",
    "            print('Issue in handle_missing_values function of MissingValHandling Class ')\n",
    "            print(err)\n",
    "\n",
    "    def merging_rare_counties(self, df):\n",
    "        ''' \n",
    "        This function is specially for \"Country_of_res\" column.\n",
    "        Some countries are occuring less than 6 times and converting all of them into one category \"Others\"\n",
    "        '''\n",
    "        try:\n",
    "            for col in df.columns:\n",
    "                df[col].replace(rare_country, 'Others', inplace= True)\n",
    "            return df\n",
    "        \n",
    "        except Exception as err:\n",
    "            print('Issue in merging_rare_counties function of MissingValHandling Class ')\n",
    "            print(err)\n",
    "\n",
    "\n",
    "missval_obj = MissingValHandling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f53cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This configuration is necessary to plot design of pipeline while fitting Pipeline \n",
    "from sklearn import set_config\n",
    "\n",
    "set_config(display='diagram')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e60e854",
   "metadata": {},
   "source": [
    "#### Column Transformer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a75072",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "* Created ColumnTransformer consisting 3 FunctionTransformers. \n",
    "* These FunctionTransformers are converting Custom Function into Transformers\n",
    "\n",
    "* FunctionTransformer-1 = It is handling outliers of two continuous columns - (age and reult) using \n",
    "    handle_outliers() function of OutliersHandling Class\n",
    "\n",
    "* FunctionTransformer-2 = It is handling Missing values of two categorical columns - (ethnicity and relation) using\n",
    "    handle_missing_values function of MissingValHandling Class\n",
    "\n",
    "* FunctionTransformer-3 = It is converting rare countries into 'Other' category - using \n",
    "    merging_rare_counties function of MissingValHandling Class\n",
    "'''\n",
    "try:\n",
    "    col_trans_1 = ColumnTransformer([\n",
    "        ('outlier', FunctionTransformer(func=outhandle_obj.handle_outliers),['age','result']),\n",
    "        ('miss_val', FunctionTransformer(func=missval_obj.handle_missing_values),['ethnicity','relation']),\n",
    "        ('rare_contry', FunctionTransformer(func=missval_obj.merging_rare_counties),['contry_of_res']),\n",
    "\n",
    "    ], remainder= 'passthrough')\n",
    "    \n",
    "except ModuleNotFoundError as err:\n",
    "    print('FunctionTransformer or ColumnTransformer are not found')\n",
    "except Exception as err:\n",
    "    print('Issue while building ColumnTransformer-1')\n",
    "    print(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b57a87d",
   "metadata": {},
   "source": [
    "#### Column Transformer 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1cc699",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "* Created ColumnTransformer consisting 2 Transformers\n",
    "\n",
    "* MinMaxScaler = Scaling values of two continuous columns -(age and result)\n",
    "\n",
    "* OneHotEncoder = Applying encoding on remaining categorical columns\n",
    "\n",
    "'''\n",
    "\n",
    "try:\n",
    "    col_trans_2 = ColumnTransformer([\n",
    "        ('scaler',MinMaxScaler(),[0,1]),\n",
    "        ('encoder', OneHotEncoder(handle_unknown = 'ignore', drop= 'first'), (slice(2,19))),\n",
    "\n",
    "    ], remainder='passthrough')\n",
    "\n",
    "except ModuleNotFoundError as err:\n",
    "    print('FunctionTransformer or ColumnTransformer are not found')\n",
    "except Exception as err:\n",
    "    print('Issue while building ColumnTransformer-2')\n",
    "    print(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854b878a",
   "metadata": {},
   "source": [
    "#### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4e1b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Created Pipeline that includes both ColumnTransformers constructed above. Pipeline consists all preprocessing steps\n",
    "'''\n",
    "try:\n",
    "    pipe = Pipeline([\n",
    "        ('col_trans_1', col_trans_1),\n",
    "        ('col_trans_2', col_trans_2)\n",
    "    ])\n",
    "\n",
    "except ModuleNotFoundError as err:\n",
    "    print('Pipeline not found')\n",
    "except Exception as err:\n",
    "    print('Issue while building Pipeline')\n",
    "    print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9193d269",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa41449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming dataset using Pipeline and converting result into dataframe\n",
    "try:\n",
    "    df_new = pipe.transform(df_train)\n",
    "    df_new = pd.DataFrame(df_new.toarray())\n",
    "    df_new\n",
    "except Exception as err:\n",
    "    print('Issue will transforming training data using Pipeline')\n",
    "    print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fbae33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline generate feature names in interger format and integer naming of input is giving warning while Model trainig.\n",
    "#Therefore, convert name of features from int to string\n",
    "\n",
    "col_str_name = [str(col) for col in df_new.columns]\n",
    "df_new.columns = col_str_name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3f0825",
   "metadata": {},
   "source": [
    "### Save Pipeline and preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4f7eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Saved new data into csv file after transforming data by appling preprocessing steps.\n",
    "This csv will be use by \"modelTraining.py\" scirpt to feed input to ML model and train different models. \n",
    "'''\n",
    "df_preprocessed = pd.concat([df_new,target],axis=1)\n",
    "\n",
    "filename = 'preprocessed_data.csv'\n",
    "\n",
    "df_preprocessed.to_csv(filename, index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9da0a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Saved pipeline as pkl; so it can be re-used in \"autism-app.py\" script while making predciton for user input.\n",
    "'''\n",
    "filename = 'autism_pipeline.pkl'\n",
    "pickle.dump(pipe, open(filename, 'wb'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
